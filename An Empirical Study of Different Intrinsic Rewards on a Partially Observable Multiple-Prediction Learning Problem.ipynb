{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "from numba import jit, cuda, roc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import math\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I have tried to recreate the results of the paper <a href = \"https://arxiv.org/abs/1906.07865\">Adapting Behavior via Intrinsic Reward: a Survey and Empirical Study.</a>\n",
    "Code base is taken from  http://jair.adaptingbehavior.com, and I have made proper changes to recreate the experiment 2 of this paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "def generate_action_data(phase_one = 50000, num_steps=150000):\n",
    "    # For the distractors each step is a random number chosen from a Normal distribution mean 0.0, var 1.0\n",
    "    #target 1\n",
    "    distractor1 = np.random.randn(phase_one)\n",
    "    random_drift = np.random.randn(num_steps-phase_one) * 0.1\n",
    "    drifter1 = np.cumsum(random_drift) + distractor1[phase_one - 1]\n",
    "    target1 = np.concatenate((distractor1, drifter1))\n",
    "    \n",
    "    #target 2\n",
    "    # At each step the drifter changes slightly by mean 0.0 and variance 0.1\n",
    "    random_drift = np.random.randn(phase_one) * 0.1\n",
    "    drifter2 = np.cumsum(random_drift)\n",
    "    distractor2 = np.random.randn(num_steps-phase_one) + drifter2[phase_one - 1]\n",
    "    target2 = np.concatenate((drifter2, distractor2))\n",
    "    \n",
    "    #target 3\n",
    "    # Constant number randomly chosen between [-50, 50]\n",
    "    constant1 = np.ones(phase_one) * np.random.uniform(-50, 50)\n",
    "    random_drift = np.random.randn(num_steps-phase_one) * 0.1\n",
    "    drifter3 = np.cumsum(random_drift) + constant1[phase_one - 1]\n",
    "    target3 = np.concatenate((constant1, drifter3))\n",
    "    \n",
    "    #target 4\n",
    "    distractor3 = np.random.randn(phase_one)\n",
    "    constant2 = np.ones(num_steps-phase_one) * np.random.uniform(-50, 50) + distractor3[phase_one - 1]\n",
    "    target4 = np.concatenate((distractor3, constant2))\n",
    "    \n",
    "    #print(target1.shape)\n",
    "    #print(target2.shape)\n",
    "    #print(target3.shape)\n",
    "    #print(target4.shape)\n",
    "    \n",
    "    return np.array([target1, target2, target3, target4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "# Plot Actions\n",
    "#plt.plot(generate_action_data().T)\n",
    "data = generate_action_data().T\n",
    "#plt.legend([\"Distractor 1\", \"Distractor 2\", \"Constant\", \"Drifter\"])\n",
    "colors = [\"red\", \"green\", \"blue\", \"black\"]\n",
    "for i in range(4):\n",
    "    plt.plot(data.T[i], color=colors[i])\n",
    "            \n",
    "plt.legend([\"Target 1: Distractor -> Drifter\",\n",
    "            \"Target 2: Drifter -> Distractor\",\n",
    "            \"Target 3: Constant -> Drifter\",\n",
    "            \"Target 4: Distractor -> Constant\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "class Autostep():\n",
    "    def __init__(self, alpha=1.0, n=1.0, h=0.0, k=0.1):\n",
    "        self.alpha = alpha\n",
    "        self.n = n\n",
    "        self.h = h\n",
    "        self.k = k\n",
    "    \n",
    "    def update(self, delta):\n",
    "        self.n = max(np.abs(delta * self.h), \n",
    "                     self.n + (1.0/10000.0) * self.alpha * (np.abs(delta * self.h) - self.n))\n",
    "        \n",
    "        self.alpha = min(self.alpha * np.exp(self.k * delta * self.h / self.n), 0.5)\n",
    "        self.h = self.h * (1 - self.alpha) + (self.alpha * delta)\n",
    "        return self.alpha, self.h, self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "class MovingAverage:\n",
    "\n",
    "    def __init__(self, beta=0.001, one=0.0, method=\"window\"):\n",
    "        self.avg = 0.0\n",
    "\n",
    "        # for time based moving average\n",
    "        self.t = 0\n",
    "\n",
    "        # for windowed moving average\n",
    "        self.one = one\n",
    "        self.beta = beta\n",
    "\n",
    "        self.method = method\n",
    "\n",
    "    def update(self, x):\n",
    "\n",
    "        if self.method == \"window\":\n",
    "            self.one = ((1.0 - self.beta) * self.one) + (self.beta * 1.0)\n",
    "            rate = self.beta / self.one\n",
    "            self.avg = ((1.0 - rate) * self.avg) + (rate * x)\n",
    "\n",
    "        if self.method == \"time\":\n",
    "            self.t += 1\n",
    "            self.avg += (x - self.avg) / self.t\n",
    "\n",
    "        return self.avg\n",
    "\n",
    "class IncrementalVariance:\n",
    "\n",
    "    def __init__(self, beta=0.001, one=0.0, method=\"window\"):\n",
    "        self.sample_mean = MovingAverage(beta=beta, one=one, method=method)\n",
    "        self.moving_variance = MovingAverage(beta=beta, one=one, method=method)\n",
    "        self.type = method\n",
    "        self.differences = []\n",
    "\n",
    "\n",
    "    def update(self, x):\n",
    "\n",
    "        old_mean = self.sample_mean.avg\n",
    "\n",
    "        # update mean\n",
    "        self.sample_mean.update(x)\n",
    "\n",
    "        # update variance\n",
    "        var_sample = (x - old_mean) * (x - self.sample_mean.avg)\n",
    "\n",
    "        self.moving_variance.update(var_sample)\n",
    "\n",
    "        return self.moving_variance.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def select_action(probs):\n",
    "    return np.random.choice(4, p=probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Intrinsic Rewards' functions: Return reward and Prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "class IntrinsicReward:\n",
    "    def __init__(self):\n",
    "        self.prediction = 0.0\n",
    "        self.stepsize = 0.0\n",
    "        self.autostep_learner = None\n",
    "        self.is_introspective = None\n",
    "\n",
    "    def update_prediction(self, x):\n",
    "        delta = x - self.prediction\n",
    "\n",
    "        if self.is_introspective:\n",
    "            self.autostep_learner.update(delta)\n",
    "            stepsize = self.autostep_learner.alpha\n",
    "        else:\n",
    "            stepsize = self.stepsize\n",
    "        \n",
    "        self.prediction += stepsize * delta\n",
    "\n",
    "        return delta\n",
    "\n",
    "class ErrorDerivative(IntrinsicReward):\n",
    "    def __init__(self, stepsize=0.03125, is_introspective=False, **kwargs):\n",
    "        self.stepsize = stepsize\n",
    "        self.is_introspective = is_introspective\n",
    "        self.eta = kwargs.get(\"eta\", 1000)\n",
    "        self.tau = kwargs.get(\"tau\", 100)\n",
    "        self.squared_errors = []\n",
    "        self.prediction = 0.0\n",
    "        self.k = kwargs.get(\"k\", 0.1)\n",
    "\n",
    "        if self.is_introspective:\n",
    "            self.autostep_learner = Autostep(k=self.k)\n",
    "    \n",
    "    def update(self, x):\n",
    "\n",
    "        delta = self.update_prediction(x)\n",
    "\n",
    "        self.squared_errors.append(np.square(delta))\n",
    "        length = len(self.squared_errors)     \n",
    "\n",
    "        if length > (self.eta + self.tau + 1):\n",
    "            first = (1.0 / (self.eta + 1)) * np.sum(self.squared_errors[-(self.eta+self.tau+1):-self.tau])\n",
    "            second = (1.0 / (self.eta + 1)) * np.sum(self.squared_errors[-(self.eta+1):])\n",
    "            return np.abs(first - second), delta\n",
    "        else:\n",
    "            return 0.0, delta\n",
    "\n",
    "class ExpectedError(IntrinsicReward):\n",
    "    def __init__(self, stepsize=0.0625, is_introspective=False, **kwargs):\n",
    "        self.stepsize = stepsize\n",
    "        self.is_introspective = is_introspective\n",
    "        self.one = 0.0\n",
    "        self.beta = kwargs.get(\"beta\", 0.01)\n",
    "        self.delta_bar = 0.0\n",
    "        self.prediction = 0.0\n",
    "        self.k = kwargs.get(\"k\", 0.1)\n",
    "\n",
    "        if self.is_introspective:\n",
    "            self.autostep_learner = Autostep(k=self.k)\n",
    "        \n",
    "    def update(self, x):\n",
    "        delta = self.update_prediction(x)\n",
    "\n",
    "        self.one = (1.0 - self.beta) * self.one + self.beta * 1.0\n",
    "        rate = self.beta / self.one\n",
    "        self.delta_bar = (1.0 - rate) * self.delta_bar + rate * delta\n",
    "\n",
    "        return np.abs(self.delta_bar), delta\n",
    "\n",
    "class StepSizeChange(IntrinsicReward):\n",
    "    def __init__(self, stepsize=0.1, is_introspective=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.previous_stepsize = 0.0\n",
    "        self.is_introspective = is_introspective\n",
    "        self.k = kwargs.get(\"k\", 0.1)\n",
    "\n",
    "        if self.is_introspective:\n",
    "            self.autostep_learner = Autostep(k=self.k)\n",
    "    \n",
    "    def update(self, x):\n",
    "        delta = self.update_prediction(x)\n",
    "        \n",
    "        if self.is_introspective:\n",
    "            stepsize = self.autostep_learner.alpha\n",
    "        else:\n",
    "            stepsize = 0.0\n",
    "\n",
    "        stepsize_change = np.abs(self.previous_stepsize - stepsize)\n",
    "        self.previous_stepsize = stepsize\n",
    "\n",
    "        return stepsize_change, delta\n",
    "\n",
    "class ErrorReduction(IntrinsicReward):\n",
    "    def __init__(self, stepsize=0.1, is_introspective=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.previous_error = 0.0\n",
    "        self.is_introspective = is_introspective\n",
    "        self.k = kwargs.get(\"k\", 0.1)\n",
    "\n",
    "        if self.is_introspective:\n",
    "            self.autostep_learner = Autostep(k=self.k)\n",
    "    \n",
    "    def update(self, x):\n",
    "        delta = self.update_prediction(x)\n",
    "        im_reward = np.abs(self.previous_error) - np.abs(delta)\n",
    "        self.previous_error = delta\n",
    "\n",
    "        return im_reward, delta\n",
    "\n",
    "class SquaredError(IntrinsicReward):\n",
    "    def __init__(self, stepsize=0.1, is_introspective=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.stepsize = stepsize\n",
    "        self.is_introspective = is_introspective\n",
    "        self.k = kwargs.get(\"k\", 0.1)\n",
    "\n",
    "        if self.is_introspective:\n",
    "            self.autostep_learner = Autostep(k=self.k)\n",
    "    \n",
    "    def update(self, x):\n",
    "        delta = self.update_prediction(x)\n",
    "        \n",
    "        return np.square(delta), delta\n",
    "\n",
    "class BayesianSurprise(IntrinsicReward):\n",
    "    def __init__(self, stepsize=0.1, is_introspective=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.stepsize = stepsize\n",
    "        self.is_introspective = is_introspective\n",
    "\n",
    "        self.previous_prediction = 0.0\n",
    "        self.previous_variance = 0.0\n",
    "        self.eta = 1.0\n",
    "        self.b = kwargs.get(\"beta\", 0.01)\n",
    "        \n",
    "        self.k = kwargs.get(\"k\", 0.1)\n",
    "\n",
    "        if self.is_introspective:\n",
    "            self.autostep_learner = Autostep(k=self.k)\n",
    "    \n",
    "    def update(self, x):\n",
    "        delta = self.update_prediction(x)\n",
    "\n",
    "        self.b = 0.01\n",
    "        self.eta = (1 - self.b) * self.eta + 1.0\n",
    "\n",
    "        welfords_var = (1 - self.b) * self.previous_variance + self.b * (x - self.previous_prediction) * (x - self.prediction)\n",
    "        var = max(welfords_var / self.eta, 10**-2)\n",
    "\n",
    "        if var != 0.0 and self.previous_variance != 0.0:\n",
    "            first = 0.5 * np.log2(var / self.previous_variance)\n",
    "            second = self.previous_variance + np.square(self.previous_prediction - self.prediction) / (2 * var)\n",
    "            im_reward = first + second - 0.5\n",
    "        else:\n",
    "            im_reward = 0.0\n",
    "        \n",
    "        self.previous_variance = np.copy(var)\n",
    "        self.previous_prediction = np.copy(self.prediction)\n",
    "\n",
    "        return im_reward,delta\n",
    "\n",
    "class UDE(IntrinsicReward):\n",
    "    def __init__(self, stepsize=0.1, is_introspective=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.stepsize = stepsize\n",
    "        self.is_introspective = is_introspective\n",
    "\n",
    "        self.one = 0.0\n",
    "        self.beta = kwargs.get(\"beta\", 0.01)\n",
    "        self.delta_bar = 0.0\n",
    "\n",
    "        self.count = 0\n",
    "        \n",
    "        self.delta_squared_avg = MovingAverage(method=\"time\")\n",
    "        self.delta_avg = MovingAverage(method=\"time\")\n",
    "\n",
    "        self.k = kwargs.get(\"k\", 0.1)\n",
    "\n",
    "        if self.is_introspective:\n",
    "            self.autostep_learner = Autostep(k=self.k)\n",
    "    \n",
    "    def update(self, x):\n",
    "        self.count += 1\n",
    "        delta = self.update_prediction(x)\n",
    "\n",
    "        self.one = (1.0 - self.beta) * self.one + self.beta * 1.0\n",
    "        rate = self.beta / self.one\n",
    "        self.delta_bar = (1.0 - rate) * self.delta_bar + rate * delta\n",
    "\n",
    "        s_bar = self.delta_squared_avg.update(np.square(delta))\n",
    "        x_bar = self.delta_avg.update(delta)\n",
    "        \n",
    "        if self.count > 30:\n",
    "            count = self.delta_avg.t\n",
    "            denom = np.sqrt((s_bar / count) - np.square(x_bar / count))\n",
    "            im_reward = np.abs(self.delta_bar / (denom + 0.00001))\n",
    "        else:\n",
    "            im_reward = 0.0\n",
    "        \n",
    "        return im_reward, delta\n",
    "\n",
    "class UncertaintyChange(IntrinsicReward):\n",
    "    def __init__(self, stepsize=0.1, is_introspective=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.stepsize = stepsize\n",
    "        self.is_introspective = is_introspective\n",
    "\n",
    "        self.beta = kwargs.get(\"beta_var\", 0.001)\n",
    "        \n",
    "        self.variance = IncrementalVariance(beta=self.beta)\n",
    "        self.previous_variance = 0.0\n",
    "\n",
    "        self.k = kwargs.get(\"k\", 0.1)\n",
    "\n",
    "        if self.is_introspective:\n",
    "            self.autostep_learner = Autostep(k=self.k)\n",
    "    \n",
    "    def update(self, x):\n",
    "        delta = self.update_prediction(x)\n",
    "\n",
    "        var = self.variance.update(self.prediction)\n",
    "        im_reward = np.abs(self.previous_variance - var)\n",
    "        self.previous_varaiance = var\n",
    "        \n",
    "        return im_reward, delta\n",
    "\n",
    "class VarianceOfPrediction(IntrinsicReward):\n",
    "    def __init__(self, stepsize=0.1, is_introspective=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.stepsize = stepsize\n",
    "        self.is_introspective = is_introspective\n",
    "        self.beta = kwargs.get(\"beta_var\", 0.001)\n",
    "        self.variance = IncrementalVariance(beta=self.beta)\n",
    "\n",
    "        self.k = kwargs.get(\"k\", 0.1)\n",
    "\n",
    "        if self.is_introspective:\n",
    "            self.autostep_learner = Autostep(k=self.k)\n",
    "    \n",
    "    def update(self, x):\n",
    "        delta = self.update_prediction(x)\n",
    "\n",
    "        im_reward = self.variance.update(self.prediction)\n",
    "        \n",
    "        return im_reward, delta\n",
    "\n",
    "class WeightChange(IntrinsicReward):\n",
    "    def __init__(self, stepsize=0.1, is_introspective=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.stepsize = stepsize\n",
    "        self.is_introspective = is_introspective\n",
    "\n",
    "        self.k = kwargs.get(\"k\", 0.1)\n",
    "\n",
    "        if self.is_introspective:\n",
    "            self.autostep_learner = Autostep(k=self.k)\n",
    "    \n",
    "    def update(self, x):\n",
    "        delta = self.update_prediction(x)\n",
    "\n",
    "        if self.is_introspective:\n",
    "            self.stepsize = self.autostep_learner.alpha\n",
    "\n",
    "        return np.abs(self.stepsize * delta), delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Bandit Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "class BehaviorAgent:\n",
    "    def __init__(self, behavior_stepsize, intrinsic_reward, is_introspective, *args, **kwargs):\n",
    "        self.intrinsic_rewards = [choose_reward(intrinsic_reward, is_introspective)[0] for _ in range(4)]\n",
    "        self.one = 0.0\n",
    "        self.r_bar = 0.0\n",
    "        self.beta = kwargs.get(\"beta_r\", 0.1)\n",
    "        self.behavior_stepsize = behavior_stepsize\n",
    "        self.action_values = np.zeros(4)\n",
    "        self.probs = np.ones(4) / 4\n",
    "        self.delta = 0\n",
    "\n",
    "    def calculate_probs(self):\n",
    "        self.probs = softmax(self.action_values)\n",
    "\n",
    "    def choose_action(self):\n",
    "        self.calculate_probs()\n",
    "        return select_action(self.probs)\n",
    "\n",
    "    def update(self, x, chosen_action):\n",
    "        # get intrinsic_reward\n",
    "        im_reward, self.delta = self.intrinsic_rewards[chosen_action].update(x)\n",
    "\n",
    "        # update_average_reward\n",
    "        self.one = (1.0 - self.beta) * self.one + self.beta * 1.0\n",
    "        rate = self.beta / self.one\n",
    "        self.r_bar = (1.0 - rate) * self.r_bar + rate * im_reward\n",
    "        \n",
    "        # Update the actions values based on the intrinsic reward\n",
    "        for action in range(4):\n",
    "            self.action_values[action] += self.behavior_stepsize * (im_reward - self.r_bar)*((action==chosen_action)*1.0 - self.probs[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "def run_experiment(num_steps=150000, is_introspective=True,\n",
    "                   record_stepsizes=False,\n",
    "                   intrinsic_reward=\"Error Derivative\"):\n",
    "    data = generate_action_data(50000, num_steps)\n",
    "    track_probs = []\n",
    "    track_stepsizes = []\n",
    "    track_error = []\n",
    "    \n",
    "    behavior_agent = BehaviorAgent(choose_reward(intrinsic_reward, is_introspective)[1], \n",
    "                                   intrinsic_reward,\n",
    "                                   is_introspective,\n",
    "                                   **choose_reward(intrinsic_reward, is_introspective)[2])\n",
    "\n",
    "    for i, step_data in enumerate(data.T):\n",
    "        chosen_action = behavior_agent.choose_action()\n",
    "\n",
    "        behavior_agent.update(step_data[chosen_action], chosen_action)\n",
    "\n",
    "        track_probs.append(np.copy(behavior_agent.probs))\n",
    "        track_error.append(np.copy(np.square(behavior_agent.delta)))\n",
    "        \n",
    "        if record_stepsizes:\n",
    "            track_stepsizes.append(np.copy(np.array([learner.autostep_learner.alpha for learner in behavior_agent.intrinsic_rewards])))\n",
    "    \n",
    "    return np.array(track_probs), np.array(track_stepsizes), np.sqrt(np.mean(track_error))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Different hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter's list\n",
    "alpha=[]\n",
    "alpha_p=[]\n",
    "beta=[]\n",
    "beta_r=[]\n",
    "\n",
    "combination_options={}\n",
    "options_non_introspective={}\n",
    "options_introspective = {}\n",
    "\n",
    "for i in range(2,9):\n",
    "    alpha.append(math.pow(2,-i))\n",
    "for i in range(2,8):\n",
    "    alpha_p.append(math.pow(2,-i))\n",
    "    \n",
    "for i in range(1,7):\n",
    "    beta.append(math.pow(10,-i))\n",
    "    beta_r.append(math.pow(10,-i))\n",
    "    \n",
    "eta=[1, 5, 10, 25, 100, 1000]\n",
    "tau=[1, 5, 10, 25, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Non-Introspective learning hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_options=0\n",
    "is_introspective = False\n",
    "\n",
    "#UDE\n",
    "alpha_p=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha_p, alpha, beta_r, beta]\n",
    "options_non_introspective[\"UDE\"] = list(itertools.product(*options))\n",
    "\n",
    "#Weight Change\n",
    "alpha_p=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha_p, alpha, beta_r]\n",
    "options_non_introspective[\"Weight Change\"] = list(itertools.product(*options))\n",
    "\n",
    "#Bayesian Surprise\n",
    "alpha_p=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha_p, alpha, beta_r, beta]\n",
    "options_non_introspective[\"Bayesian Surprise\"] = list(itertools.product(*options))\n",
    "\n",
    "#Squared Error\n",
    "alpha_p=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha_p, alpha, beta_r]\n",
    "options_non_introspective[\"Squared Error\"] = list(itertools.product(*options))\n",
    "\n",
    "\n",
    "#Expected Error\n",
    "alpha_p=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha_p, alpha, beta_r, beta]\n",
    "options_non_introspective[\"Expected Error\"] = list(itertools.product(*options))\n",
    "\n",
    "#Variance of Prediction\n",
    "alpha_p=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_var=[] # put your desired list of values here\n",
    "options = [alpha_p, alpha, beta_r, beta_var]\n",
    "options_non_introspective[\"Variance of Prediction\"] = list(itertools.product(*options))\n",
    "\n",
    "\n",
    "#Error Derivative\n",
    "alpha_p=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "eta=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "tau=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha_p, alpha, beta_r, eta, tau]\n",
    "options_non_introspective[\"Error Derivative\"] = list(itertools.product(*options))\n",
    "\n",
    "#Step-size Change\n",
    "alpha_p=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha_p, alpha, beta_r]\n",
    "options_non_introspective[\"Step-size Change\"] = list(itertools.product(*options))\n",
    "\n",
    "#Error Reduction\n",
    "alpha_p=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha_p, alpha, beta_r]\n",
    "options_non_introspective[\"Error Reduction\"] = list(itertools.product(*options))\n",
    "\n",
    "#Uncertainty Change\n",
    "alpha_p=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_var=[] # put your desired list of values here\n",
    "options = [alpha_p, alpha, beta_r, beta_var]\n",
    "options_non_introspective[\"Uncertainty Change\"] = list(itertools.product(*options))\n",
    "\n",
    "\n",
    "combination_options[is_introspective] = options_non_introspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Introspective learner's hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_options=0\n",
    "is_introspective = True\n",
    "\n",
    "#UDE\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha, beta_r, beta]\n",
    "options_introspective[\"UDE\"] = list(itertools.product(*options))\n",
    "\n",
    "#Weight Change\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha, beta_r]\n",
    "options_introspective[\"Weight Change\"] = list(itertools.product(*options))\n",
    "\n",
    "#Bayesian Surprise\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha, beta_r, beta]\n",
    "options_introspective[\"Bayesian Surprise\"] = list(itertools.product(*options))\n",
    "\n",
    "#Squared Error\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha, beta_r]\n",
    "options_introspective[\"Squared Error\"] = list(itertools.product(*options))\n",
    "\n",
    "\n",
    "#Expected Error\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha, beta_r, beta]\n",
    "options_introspective[\"Expected Error\"] = list(itertools.product(*options))\n",
    "\n",
    "#Variance of Prediction\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_var=[] # put your desired list of values here\n",
    "options = [alpha, beta_r, beta_var]\n",
    "options_introspective[\"Variance of Prediction\"] = list(itertools.product(*options))\n",
    "\n",
    "\n",
    "#Error Derivative\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "eta=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "tau=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha, beta_r, eta, tau]\n",
    "options_introspective[\"Error Derivative\"] = list(itertools.product(*options))\n",
    "\n",
    "#Step-size Change\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha, beta_r]\n",
    "options_introspective[\"Step-size Change\"] = list(itertools.product(*options))\n",
    "\n",
    "#Error Reduction\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "options = [alpha, beta_r]\n",
    "options_introspective[\"Error Reduction\"] = list(itertools.product(*options))\n",
    "\n",
    "#Uncertainty Change\n",
    "alpha=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_r=[] # put your desired list of values here or use the corresponding variable from the previous cell.\n",
    "beta_var=[] # put your desired list of values here\n",
    "options = [alpha, beta_r, beta_var]\n",
    "options_introspective[\"Uncertainty Change\"] = list(itertools.product(*options))\n",
    "\n",
    "\n",
    "combination_options[is_introspective] = options_introspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "def choose_reward(name, is_introspective):\n",
    "    if name == \"UDE\":\n",
    "        if is_introspective:\n",
    "            return (UDE(stepsize=1.0,\n",
    "                        is_introspective=True),\n",
    "                     combination_options[is_introspective][name][track_options][0],\n",
    "                    {\"beta_r\":combination_options[is_introspective][name][track_options][1],\n",
    "                     \"beta\": combination_options[is_introspective][name][track_options][2],\n",
    "                     \"k\": 0.01})\n",
    "        else:\n",
    "            return (UDE(stepsize=combination_options[is_introspective][name][track_options][0],\n",
    "                        is_introspective=False),\n",
    "                    combination_options[is_introspective][name][track_options][1],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][2],\n",
    "                     \"beta\": combination_options[is_introspective][name][track_options][3]})\n",
    "    elif name == \"Weight Change\":\n",
    "        if is_introspective:\n",
    "            return (WeightChange(stepsize=1.0,\n",
    "                                 is_introspective=True),\n",
    "                    combination_options[is_introspective][name][track_options][0],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][1],\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (WeightChange(stepsize=combination_options[is_introspective][name][track_options][0],\n",
    "                                 is_introspective=False),\n",
    "                    combination_options[is_introspective][name][track_options][1],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][2]})\n",
    "        \n",
    "    elif name == \"Bayesian Surprise\":\n",
    "        if is_introspective:\n",
    "            return (BayesianSurprise(stepsize=1.0,\n",
    "                                     is_introspective=True),\n",
    "                    combination_options[is_introspective][name][track_options][0],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][1],\n",
    "                     \"beta\": combination_options[is_introspective][name][track_options][2],\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (BayesianSurprise(stepsize=combination_options[is_introspective][name][track_options][0],\n",
    "                                     is_introspective=False),\n",
    "                    combination_options[is_introspective][name][track_options][1],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][2],\n",
    "                     \"beta\": combination_options[is_introspective][name][track_options][3]})\n",
    "        \n",
    "    elif name == \"Squared Error\":\n",
    "        if is_introspective:\n",
    "            return (SquaredError(stepsize=1.0,\n",
    "                                 is_introspective=True),\n",
    "                    combination_options[is_introspective][name][track_options][0],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][1],\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (SquaredError(stepsize=combination_options[is_introspective][name][track_options][0],\n",
    "                                 is_introspective=False),\n",
    "                    combination_options[is_introspective][name][track_options][1],\n",
    "                    {\"beta_r\":combination_options[is_introspective][name][track_options][2]})\n",
    "        \n",
    "        \n",
    "    elif name == \"Expected Error\":\n",
    "        if is_introspective:\n",
    "            return (ExpectedError(stepsize=1.0,\n",
    "                                  is_introspective=True),\n",
    "                    combination_options[is_introspective][name][track_options][0],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][1],\n",
    "                     \"beta\": combination_options[is_introspective][name][track_options][2],\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (ExpectedError(stepsize=combination_options[is_introspective][name][track_options][0],\n",
    "                                  is_introspective=False),\n",
    "                    combination_options[is_introspective][name][track_options][1],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][2],\n",
    "                     \"beta\": combination_options[is_introspective][name][track_options][3]})\n",
    "        \n",
    "    elif name == \"Variance of Prediction\":\n",
    "        if is_introspective:\n",
    "            return (VarianceOfPrediction(stepsize=1.0,\n",
    "                                         is_introspective=True),\n",
    "                     combination_options[is_introspective][name][track_options][0],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][1],\n",
    "                     \"beta_var\": combination_options[is_introspective][name][track_options][2],\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (VarianceOfPrediction(stepsize=combination_options[is_introspective][name][track_options][0],\n",
    "                                         is_introspective=False),\n",
    "                    combination_options[is_introspective][name][track_options][1],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][2],\n",
    "                     \"beta_var\": combination_options[is_introspective][name][track_options][3] #0.00001\n",
    "                    })\n",
    "    elif name == \"Error Derivative\":\n",
    "        if is_introspective:\n",
    "            return (ErrorDerivative(stepsize=1.0,\n",
    "                                    is_introspective=True),\n",
    "                    combination_options[is_introspective][name][track_options][0],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][1],\n",
    "                     \"eta\": combination_options[is_introspective][name][track_options][2],\n",
    "                     \"tau\": combination_options[is_introspective][name][track_options][3],\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (ErrorDerivative(stepsize=combination_options[is_introspective][name][track_options][0],\n",
    "                                   is_introspective=False),\n",
    "                    combination_options[is_introspective][name][track_options][1],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][2],\n",
    "                     \"eta\": combination_options[is_introspective][name][track_options][3],#1000,\n",
    "                     \"tau\": combination_options[is_introspective][name][track_options][4]})#100.0})\n",
    "    elif name == \"Step-size Change\":\n",
    "        if is_introspective:\n",
    "            return (StepSizeChange(stepsize=1.0,\n",
    "                                  is_introspective=True),\n",
    "                    combination_options[is_introspective][name][track_options][0],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][1],\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (StepSizeChange(stepsize=combination_options[is_introspective][name][track_options][0],\n",
    "                                  is_introspective=False),\n",
    "                    combination_options[is_introspective][name][track_options][1],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][2]})\n",
    "    \n",
    "    elif name == \"Error Reduction\":\n",
    "        if is_introspective:\n",
    "            return (ErrorReduction(stepsize=1.0,\n",
    "                                   is_introspective=True),\n",
    "                    combination_options[is_introspective][name][track_options][0],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][1],\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (ErrorReduction(stepsize=combination_options[is_introspective][name][track_options][0],\n",
    "                                   is_introspective=False),\n",
    "                    combination_options[is_introspective][name][track_options][1],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][2]})\n",
    "    elif name == \"Uncertainty Change\":\n",
    "        if is_introspective:\n",
    "            return (UncertaintyChange(stepsize=1.0,\n",
    "                                      is_introspective=True),\n",
    "                    combination_options[is_introspective][name][track_options][0],\n",
    "                    {\"beta_r\": combination_options[is_introspective][name][track_options][1],\n",
    "                     \"beta_var\": combination_options[is_introspective][name][track_options][2],\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (UncertaintyChange(stepsize=combination_options[is_introspective][name][track_options][0],\n",
    "                                      is_introspective=False),\n",
    "                    combination_options[is_introspective][name][track_options][1],\n",
    "                    {\"beta_r\":combination_options[is_introspective][name][track_options][2],\n",
    "                     \"beta_var\": combination_options[is_introspective][name][track_options][3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "def run(reward, choose_introspective = True, choose_runs = 2):\n",
    "    output = widgets.Output()\n",
    "\n",
    "    print(\"Running for \"+ str(combination_options[choose_introspective][reward][track_options]))\n",
    "    \n",
    "    \n",
    "    runs = [run_experiment(intrinsic_reward=reward, is_introspective=choose_introspective) for _ in range(choose_runs)]\n",
    "    runs_probs = [runs[i][0] for i in range(len(runs))]\n",
    "    RMSE = [runs[i][2] for i in range(len(runs))]\n",
    "    \n",
    "    print(\"*****RMSE**********\")\n",
    "    print(np.mean(RMSE))\n",
    "    print(\"******************\")\n",
    "    action_probs = np.mean(runs_probs, axis=0)\n",
    "    with output:\n",
    "        fig = plt.figure(figsize=(4,5))\n",
    "        fig.suptitle(reward, fontsize=10, y=0.92)\n",
    "        colors = [\"red\", \"green\", \"blue\", \"black\"]\n",
    "        for i in range(4):\n",
    "            plt.plot(action_probs.T[i], color=colors[i])\n",
    "        #plt.legend([\"Target 1: Distractor -> Drifter\",\n",
    "        #    \"Target 2: Drifter -> Distractor\",\n",
    "        #    \"Target 3: Constant -> Drifter\",\n",
    "        #    \"Target 4: Distractor -> Constant\"], bbox_to_anchor=(0.599, 1.28), loc='center right')\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        #plt.xlim([0,150000])\n",
    "        plt.xticks(np.arange(0, 150000+1, 50000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Non-Introspective Learning: Below sample code is given for two rewards. We can use it for other rewards- we just need to change the 'reward' name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_options = 0\n",
    "choose_introspective = False\n",
    "reward = \"Bayesian Surprise\"\n",
    "for i in range(len(combination_options[choose_introspective][reward])):\n",
    "    run(choose_introspective = False, choose_runs = 200, reward = reward)\n",
    "    track_options = track_options + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_options = 0\n",
    "choose_introspective = False\n",
    "reward = \"Variance of Prediction\"\n",
    "for i in range(len(combination_options[choose_introspective][reward])):\n",
    "    run(choose_introspective = False, choose_runs = 200, reward = reward)\n",
    "    track_options = track_options + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Introspective Learning: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_options = 0\n",
    "choose_introspective = True\n",
    "reward = \"Bayesian Surprise\"\n",
    "for i in range(len(combination_options[choose_introspective][reward])):\n",
    "    run(choose_introspective = False, choose_runs = 200, reward = reward)\n",
    "    track_options = track_options + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Figure with all hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "def run(reward, choose_introspective = True, choose_runs = 2):\n",
    "    output = widgets.Output()\n",
    "\n",
    "    print(\"Running for \"+ str(combination_options[choose_introspective][reward][track_options]))\n",
    "    \n",
    "    \n",
    "    runs = [run_experiment(intrinsic_reward=reward, is_introspective=choose_introspective) for _ in range(choose_runs)]\n",
    "    runs_probs = [runs[i][0] for i in range(len(runs))]\n",
    "    RMSE = [runs[i][2] for i in range(len(runs))]\n",
    "    \n",
    "    print(\"*****RMSE**********\")\n",
    "    print(np.mean(RMSE))\n",
    "    print(\"******************\")\n",
    "    action_probs = np.mean(runs_probs, axis=0)\n",
    "    with output:\n",
    "        fig = plt.figure(figsize=(4,5))\n",
    "        #Show the hyper-parameters on the figure\n",
    "        fig.suptitle(str(combination_options[choose_introspective][reward][track_options]), fontsize=10, y=0.92)\n",
    "        colors = [\"red\", \"green\", \"blue\", \"black\"]\n",
    "        for i in range(4):\n",
    "            plt.plot(action_probs.T[i], color=colors[i])\n",
    "        #plt.legend([\"Target 1: Distractor -> Drifter\",\n",
    "        #    \"Target 2: Drifter -> Distractor\",\n",
    "        #    \"Target 3: Constant -> Drifter\",\n",
    "        #    \"Target 4: Distractor -> Constant\"], bbox_to_anchor=(0.599, 1.28), loc='center right')\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.xticks(np.arange(0, 150000+1, 50000))\n",
    "        \n",
    "track_options = 0\n",
    "choose_introspective = False\n",
    "reward = \"Variance of Prediction\"\n",
    "for i in range(len(combination_options[choose_introspective][reward])):\n",
    "    run(choose_introspective = False, choose_runs = 5, reward = reward)\n",
    "    track_options = track_options + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did not able to check all combinations of the hyper-parameters due to limited computational resource and time constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "def choose_reward(name, is_introspective):\n",
    "    if name == \"Error Derivative\":\n",
    "        if is_introspective:\n",
    "            return (ErrorDerivative(stepsize=1.0,\n",
    "                                    is_introspective=True),\n",
    "                     0.003906,\n",
    "                    {\"beta_r\": 0.1,\n",
    "                     \"eta\": 1000,\n",
    "                     \"tau\": 1,\n",
    "                     \"k\": 0.1})\n",
    "        else:#(0.03125, 0.007812, 0.001)\n",
    "            return (ErrorDerivative(stepsize=0.03125,\n",
    "                                   is_introspective=False),\n",
    "                    0.007812,\n",
    "                    {\"beta_r\": 0.001,\n",
    "                     \"eta\": 1000,\n",
    "                     \"tau\": 100})\n",
    "    \n",
    "    elif name == \"Expected Error\":\n",
    "        if is_introspective:\n",
    "            return (ExpectedError(stepsize=1.0,\n",
    "                                  is_introspective=True),\n",
    "                    0.0078125,\n",
    "                    {\"beta_r\": 0.1,\n",
    "                     \"beta\": 0.001,\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (ExpectedError(stepsize=0.0625,\n",
    "                                  is_introspective=False),\n",
    "                    0.0078125,\n",
    "                    {\"beta_r\": 0.1,\n",
    "                     \"beta\": 0.1})\n",
    "    \n",
    "    elif name == \"Step-size Change\":\n",
    "        if is_introspective:\n",
    "            return (StepSizeChange(stepsize=1.0,\n",
    "                                  is_introspective=True),\n",
    "                    0.25,\n",
    "                    {\"beta_r\": 0.0001,\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (StepSizeChange(stepsize=0.1,\n",
    "                                  is_introspective=False),\n",
    "                    0.1,\n",
    "                    {\"beta_r\": 0.001})\n",
    "    \n",
    "    elif name == \"Error Reduction\":\n",
    "        if is_introspective:\n",
    "            return (ErrorReduction(stepsize=1.0,\n",
    "                                   is_introspective=True),\n",
    "                    0.003906,\n",
    "                    {\"beta_r\": 0.1,\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (ErrorReduction(stepsize=0.125,\n",
    "                                   is_introspective=False),\n",
    "                    0.003906,\n",
    "                    {\"beta_r\": 0.1})\n",
    "    \n",
    "    elif name == \"Squared Error\":\n",
    "        if is_introspective:\n",
    "            return (SquaredError(stepsize=1.0,\n",
    "                                 is_introspective=True),\n",
    "                    0.0078125,\n",
    "                    {\"beta_r\": 0.1,\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (SquaredError(stepsize=0.015625,\n",
    "                                 is_introspective=False),\n",
    "                    0.003906,\n",
    "                    {\"beta_r\": 0.01})\n",
    "    \n",
    "    elif name == \"Bayesian Surprise\":\n",
    "        if is_introspective:\n",
    "            return (BayesianSurprise(stepsize=1.0,\n",
    "                                     is_introspective=True),\n",
    "                    0.003906,\n",
    "                    {\"beta_r\": 0.1,\n",
    "                     \"beta\": 0.01,\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (BayesianSurprise(stepsize=0.03125,\n",
    "                                     is_introspective=False),\n",
    "                    0.003906,\n",
    "                    {\"beta_r\": 0.1,\n",
    "                     \"beta\": 0.01})\n",
    "    \n",
    "    elif name == \"UDE\":\n",
    "        if is_introspective:\n",
    "            return (UDE(stepsize=1.0,\n",
    "                        is_introspective=True),\n",
    "                    0.25,\n",
    "                    {\"beta_r\": 0.1,\n",
    "                     \"beta\": 0.001,\n",
    "                     \"k\": 0.01})\n",
    "        else:\n",
    "            return (UDE(stepsize=0.0625,\n",
    "                        is_introspective=False),\n",
    "                    0.125,\n",
    "                    {\"beta_r\": 0.1,\n",
    "                     \"beta\": 0.1})\n",
    "    \n",
    "    elif name == \"Uncertainty Change\":\n",
    "        if is_introspective:\n",
    "            return (UncertaintyChange(stepsize=1.0,\n",
    "                                      is_introspective=True),\n",
    "                    0.0078125,\n",
    "                    {\"beta_r\": 0.0001,\n",
    "                     \"beta_var\": 0.1,\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (UncertaintyChange(stepsize=0.25,\n",
    "                                      is_introspective=False),\n",
    "                    0.00390625,\n",
    "                    {\"beta_r\": 0.01,\n",
    "                     \"beta_var\": 0.01})\n",
    "    \n",
    "    elif name == \"Variance of Prediction\":\n",
    "        if is_introspective:\n",
    "            return (VarianceOfPrediction(stepsize=1.0,\n",
    "                                         is_introspective=True),\n",
    "                    0.003906,\n",
    "                    {\"beta_r\": 0.0001,\n",
    "                     \"beta_var\": 0.1,\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (VarianceOfPrediction(stepsize=0.25,\n",
    "                                         is_introspective=False),\n",
    "                    0.25,\n",
    "                    {\"beta_r\": 0.00001, \n",
    "                     \"beta_var\": 0.000001\n",
    "                    })\n",
    "    \n",
    "    elif name == \"Weight Change\":\n",
    "        if is_introspective:\n",
    "            return (WeightChange(stepsize=1.0,\n",
    "                                 is_introspective=True),\n",
    "                    0.007812,\n",
    "                    {\"beta_r\": 0.01,\n",
    "                     \"k\": 0.1})\n",
    "        else:\n",
    "            return (WeightChange(stepsize=0.0625,\n",
    "                                 is_introspective=False),\n",
    "                    0.003906,\n",
    "                    {\"beta_r\": 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run non-introspective and introspective learners for all intrinsic rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "def run(choose_introspective = True, choose_runs = 2):\n",
    "    output = widgets.Output()\n",
    "    options=[\"Error Derivative\", \"Expected Error\", \"Step-size Change\", \n",
    "                \"Error Reduction\", \"Squared Error\", \"Bayesian Surprise\", \n",
    "                \"UDE\", \"Uncertainty Change\", \"Variance of Prediction\", \"Weight Change\"]\n",
    "         \n",
    "    for reward in options:\n",
    "        print(\"Running for \"+ reward)\n",
    "        runs = [run_experiment(intrinsic_reward=reward, is_introspective=choose_introspective)[0] for _ in range(choose_runs)]\n",
    "        action_probs = np.mean(runs, axis=0)\n",
    "        with output:\n",
    "            fig = plt.figure(figsize=(4,5))\n",
    "            fig.suptitle(reward, fontsize=10, y=0.92)\n",
    "            colors = [\"red\", \"green\", \"blue\", \"black\"]\n",
    "            for i in range(4):\n",
    "                plt.plot(action_probs.T[i], color=colors[i])\n",
    "            #plt.legend([\"Target 1: Distractor -> Drifter\",\n",
    "            #    \"Target 2: Drifter -> Distractor\",\n",
    "            #    \"Target 3: Constant -> Drifter\",\n",
    "            #    \"Target 4: Distractor -> Constant\"], bbox_to_anchor=(0.599, 1.28), loc='center right')\n",
    "            plt.ylim([0.0, 1.0])\n",
    "            #plt.xlim([0,150000])\n",
    "            plt.xticks(np.arange(0, 150000+1, 50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(choose_introspective = False, choose_runs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(choose_introspective = True, choose_runs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Individual Intrinsic Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "def run():\n",
    "  output = widgets.Output()\n",
    "  button = widgets.Button(description=\"Run Experiment\")\n",
    "\n",
    "  choose_reward = widgets.Dropdown(\n",
    "      options=[\"Error Derivative\", \"Expected Error\", \"Step-size Change\", \n",
    "                \"Error Reduction\", \"Squared Error\", \"Bayesian Surprise\", \n",
    "                \"UDE\", \"Uncertainty Change\", \"Variance of Prediction\", \"Weight Change\"],\n",
    "      value=\"Weight Change\",\n",
    "      description=\"Choose Reward:\",\n",
    "      disabled=False,\n",
    "      style={'description_width': 'initial'},\n",
    "  )\n",
    "\n",
    "  choose_runs = widgets.IntText(description=\"Choose number of runs:\", value=2, style={'description_width': 'initial'},)\n",
    "  choose_introspective = widgets.Checkbox(value=True, description=\"Use Introspective Learners?\")\n",
    "\n",
    "  def reset_displays():\n",
    "      clear_output()\n",
    "      display(choose_reward)\n",
    "      display(choose_runs)\n",
    "      display(choose_introspective)\n",
    "      display(button)\n",
    "\n",
    "  def on_button_click(b):\n",
    "      reset_displays()\n",
    "      reward = choose_reward.value\n",
    "      print(\"Running\")\n",
    "      runs = [run_experiment(intrinsic_reward=reward, is_introspective=choose_introspective.value)[0] for _ in range(choose_runs.value)]\n",
    "      action_probs = np.mean(runs, axis=0)\n",
    "      with output:\n",
    "            fig = plt.figure(figsize=(4,5))\n",
    "\n",
    "            fig.suptitle(reward, fontsize=10, y=0.92)\n",
    "\n",
    "            colors = [\"red\", \"green\", \"blue\", \"black\"]\n",
    "            for i in range(4):\n",
    "                plt.plot(action_probs.T[i], color=colors[i])\n",
    "            #plt.legend([\"Target 1: Distractor -> Drifter\",\n",
    "            #    \"Target 2: Drifter -> Distractor\",\n",
    "            #    \"Target 3: Constant -> Drifter\",\n",
    "            #    \"Target 4: Distractor -> Constant\"], bbox_to_anchor=(0.599, 1.28), loc='center right')\n",
    "            plt.ylim([0.0, 1.0])\n",
    "            #plt.xlim([0,150000])\n",
    "            plt.xticks(np.arange(0, 150000+1, 50000))\n",
    "\n",
    "  button.on_click(on_button_click)\n",
    "  reset_displays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Step-size parameter alpha_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(reward, choose_introspective = True, choose_runs = 2):\n",
    "    output = widgets.Output()\n",
    "\n",
    "    print(\"Running for \"+ str(combination_options[choose_introspective][reward][track_options]))\n",
    "    runs = [run_experiment(intrinsic_reward=reward, is_introspective=choose_introspective) for _ in range(choose_runs)]\n",
    "    runs_probs = [runs[i][0] for i in range(len(runs))]\n",
    "    RMSE = [runs[i][2] for i in range(len(runs))]\n",
    "    \n",
    "    print(\"*****RMSE**********\")\n",
    "    print(np.mean(RMSE))\n",
    "    print(\"******************\")\n",
    "    action_probs = np.mean(runs_probs, axis=0)\n",
    "    with output:\n",
    "        fig = plt.figure(figsize=(4,5))\n",
    "        fig.suptitle(str(combination_options[choose_introspective][reward][track_options][0]), fontsize=10, y=0.92)\n",
    "        colors = [\"red\", \"green\", \"blue\", \"black\"]\n",
    "        for i in range(4):\n",
    "            plt.plot(action_probs.T[i], color=colors[i])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.xticks(np.arange(0, 150000+1, 50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Squared Error\n",
    "alpha_p=[]\n",
    "for i in range(2,8):\n",
    "    alpha_p.append(math.pow(2,-i))\n",
    "alpha = [0.003906]\n",
    "beta = [0.01]\n",
    "\n",
    "options = [alpha_p, alpha, beta]\n",
    "options_non_introspective[\"Squared Error\"]= list(itertools.product(*options))\n",
    "\n",
    "combination_options[False] = options_non_introspective\n",
    "print(combination_options[False][\"Squared Error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_options = 0\n",
    "choose_introspective = False\n",
    "reward = \"Squared Error\"\n",
    "for i in range(len(combination_options[choose_introspective][reward])):\n",
    "    run(choose_introspective = False, choose_runs = 200, reward = reward)\n",
    "    track_options = track_options + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian Surprise\n",
    "alpha_p=[]\n",
    "for i in range(2,8):\n",
    "    alpha_p.append(math.pow(2,-i))\n",
    "    \n",
    "beta_r=[0.1]\n",
    "beta = [0.01]\n",
    "alpha = [0.003906]\n",
    "\n",
    "options=[alpha_p,alpha, beta_r, beta]\n",
    "options_non_introspective[\"Bayesian Surprise\"]= list(itertools.product(*options))\n",
    "\n",
    "combination_options[False] = options_non_introspective\n",
    "print(combination_options[False][\"Bayesian Surprise\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_options = 0\n",
    "choose_introspective = False\n",
    "reward = \"Bayesian Surprise\"\n",
    "for i in range(len(combination_options[choose_introspective][reward])):\n",
    "    run(choose_introspective = False, choose_runs = 200, reward = reward)\n",
    "    track_options = track_options + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
